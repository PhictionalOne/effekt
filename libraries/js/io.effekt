module io

import mutable/ref
import mutable/queue

// Asynchronous I/O
// ----------------

interface AsyncIO {
  /**
   * Runs the provided computation and conceptually waits until it completes by
   * calling the writer-continuation.
   *
   * The provided writer-continuation should only ever be called ONCE.
   * The computation is passed as a thunk in order to prevent accidental usage of
   * other control effects that would violate the contract of calling the writer
   * once.
   */
  def performIO[T](computation: (T => Unit at {io,global}) => Unit at {io,global}): T
}

namespace AsyncIO {
  /**
   * Run an IO computation (that uses callbacks) here.
   */
  def run(program: () => Unit / AsyncIO at {io, global}): Unit =
    try { program() }
    with AsyncIO {
      def performIO[T](computation) = computation(resume)
    }
}


interface Process {
  def fork(p: Task[Unit]): Unit
  def yield(): Unit
  def exit(): Nothing
}


// Promises
// --------

interface Promises {
  def promise[T](p: Task[T]): Promise[T]
  def await[T](p: Promise[T]): T
}

type PromiseState[T] {
  Unresolved()
  Resolved(value: T)
  Awaited(callbacks: List[T => Unit at {io, global}])
}

// In Haskell this is called `IVar`
type Promise[T] = Ref[PromiseState[T]]

// TODO we cannot add effects Files, Console, etc. to Task since modules cannot be recursive, at the moment.
effect IO = { AsyncIO, Process, Promises }

type Task[T] = () => T / IO at {io, global}


// Event Loop
// ----------

extern io def schedule(k: () => Unit at {io, global}): Unit =
  "setTimeout(() => (${k})().run(), 0)"


def eventloop(prog: Task[Unit]) = {

  def queue: Queue[() => Unit at {io, global}] = emptyQueue(32);

  var openIOTasks in global = 0;

  def run(): Unit =
    queue.popBack() match {
      case Some(k) =>
        schedule(box { k(); run() })
      case None() and openIOTasks > 0 =>
        // Busy waiting
        // Using openIOTasks and busy waiting is mostly for instructive purposes.
        // Instead, we could also make sure a call to `run()` is part of the captured continuation
        // of the IO task to "wake up" the scheduler.
        schedule(run)
      case _ => ()
    }

  def handle(p: Task[Unit]): Unit =
    try { p() }
    with Process {
      def yield() = {
        queue.pushFront(box { resume(()) })
      }

      def fork(task) = {
        queue.pushFront(box { resume(()) })
        handle(task)
      }

      def exit() = {
        ()
      }
    }
    with AsyncIO {
      def performIO[T](computation) = {
        openIOTasks = openIOTasks + 1
        computation(box { res =>
          openIOTasks = openIOTasks - 1;
          // Move task to the ready-queue
          queue.pushFront(box { resume(res) })
        })
      }
    }
    with Promises {
      def promise[T](task) = {
        def resolve[T](p: Promise[T], v: T): Unit = p.get match {
          case Unresolved() => p.set(Resolved(v))
          case Resolved(v) => panic("Promise already resolved")
          case Awaited(ks) =>
            p.set(Resolved(v))
            ks.foreach { k =>
              queue.pushBack(box { k(v) })
            }
        }

        val promise: Promise[T] = fresh(Unresolved());
        queue.pushFront(box {  resume(promise) })
        handle(box { resolve(promise, task()) })
      }
      def await[T](promise) = promise.get match {
        case Unresolved() => promise.set(Awaited(Cons(resume, Nil())))
        case Resolved(v) => resume(v)
        case Awaited(ks) => promise.set(Awaited(Cons(resume, ks)))
      }
    }


  // implement the concurrency / io actions (collecting tasks)
  handle(prog);

  // run the scheduler
  run()
}